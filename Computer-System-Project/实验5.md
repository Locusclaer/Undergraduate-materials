# 分布式计算框架 MapReduce
|姓名|学号|成绩评定|
|----|----|----|
|翟一航|23020011046||

## 1. 实验目的
1. 通过实验，理解 MapReduce 框架的基本原理，掌握 MapReduce 框架的 Map 阶段和 Reduce 阶段的执行流程，以及数据的划分、传输和聚合过程，具备使用 MapReduce 进行简单的分布式数据处理，并能通过进一步自学进行更为复杂的分布式数据处理，从而掌握使用 MapReduce 进行大数据处理的基本系统设计能力。
2. 通过程序验证，理解性能优化中的并发技术对时延和吞吐率的影响，掌握用并发技术提升系统性能的设计思想。
3. 通过观察分析，理解系统的可并行性与不可并行性的差异，理解工程实践中的并行不完备问题，通过思考该问题，训练理解和处理工程实践冲突和设计实现差异的思维能力。
4. 通过实验准备和作业提交过程中的论文查阅（MapReduce2004），逐步掌握外文专业文献的检索、学习和应用能力。

## 2. 实验过程与习题
### 2.1 WordCount
#### 问题1:WordCount 的__init__方法的参数是 maptask 和 reducetask，简单地解释一下这两个变量都控制了什么？
```python
def __init__(self, maptask, reducetask, path):
    MapReduce.__init__(self,  maptask, reducetask, path)
```
其中的 maptask 和 reducetask 参数分别用于控制 map 和 reduce 阶段的并行度。maptask 参数表示将输入的文件划分成多少个片段，即由多少个 map 进程来并行处理输入文件。reducetask 参数表述将 map 阶段的输出划分为多少个 reduce 分区，即由多少个 reduce 进程来并行处理 map 阶段输出的 key 分区。这两个参数越大表示 map 和 reduce 阶段引入的并行线程数量越多，运行速度在性能允许的情况下会越快。

#### 问题2:简要解释调用 run 如何触发对 WordCount 实例的 map 和 reduce 方法的调用。
run() 函数如下：
```python
def run(self):
    pool = Pool(processes=max(self.maptask, self.reducetask))
    regions = pool.map(self.doMap, range(0, self.maptask))
    partitions = pool.map(self.doReduce, range(0, self.reducetask))
```
首先函数的第一行，创建了一个进程池，用于执行并发任务。第二行启动多个进程，每个进程都调用`self.doMap`，在`doMap()`函数中，又通过`keyvaluelist = self.Map(keyvalue, value)`调用了`Map()`函数，又进而 pass 到 WordCount 中重写的`Map()`方法。同理，第三行也启动多个进程，每个进程都调用`self.doReduce`，在`doReduce()`函数中，又通过`out.append(self.Reduce(k, keys[k]))`调用了`Reduce()`函数，又进而 pass 到 WordCount 中重写的`Reduce()`方法。

### 2.2 Map 和 Reduce
#### 问题3:WordCount 中 map 方法的参数 keyvalue 和 value 代表什么？
- keyvalue：代表输入文件中当前分片的起始字节偏移量，它是一个字符串，格式为 数据在原始文件中的偏移量:实际数据内容，它用于标识并定位当前处理的文件块，但是在`WordCount`类的`Map()`实现中虽然传入了该参数但是并没有使用它，这是因为进行单词计数不需要定位单词的位置。
- value：代表 Map 任务处理的文件内容片段，是输入文件的一部分，也是 keyvalue 除去偏移量后的部分，它是一个字符串（一段文本或者单词），`Map()`对它进行扫描提取出目标单词。

#### 问题4:WordCount 中 reduce 方法的参数 key 和 keyvalues 代表什么？
- key：代表中间键值对的键，表示的是某个具体的单词，并且此时都已经被转为小写，由 Map 阶段输出。
- keyvalues：这是一个键值对列表，包含参数 key 对应的所有 (key, value) 元组，每个元素的 value 都是 1，可能来自不同的 Map 分片。

### 2.3 Map 和 Reduce 的并行
#### 问题5:doMap 有多少调用，doReduce 有多少调用？为什么？
在`MapReduce`类的`Run()`方法中，可以发现如下代码：

`regions = pool.map(self.doMap, range(0, self.maptask))`

`partitions = pool.map(self.doReduce, range(0, self.reducetask))`

可以发现 doMap 和 doReduce 的调用次数取决于 maptask 和 reducetask，即 map 和 reduce 的任务数量。

在主程序中有：

```python
wc = WordCount(2, 2, sys.argv[1])
wc.run()
```

因而 maptask = 2，reducetask = 2，故 doMap 和 doReduce 都分别调用了 2 次。

#### 问题6:假设有足够的内核，哪些调用是并行运行的？
Map 阶段创建 maptask 个子进程，每个进程并行执行 doMap 处理各自的文件分片，Reduce 阶段创建 reducetask 个子进程，每个进程并行执行 doReduce 处理各自的分区。这是因为 doMap 与 doReduce 都通过进程池`pool = Pool(processes=max(self.maptask, self.reducetask),)`来执行，因而在进程池足够大，当内核也足够时，所有的 map 任务会并行执行，之后 reduce 任务也会并行执行，但是由于 reduce 任务依赖于 map 任务的输出，因而 map 与 reduce 阶段的执行是串行的。

#### 问题7:对于 maptask 和 reducetask 参数的值，哪一个影响到了程序的运行时间？为什么有的参数不会对程序的运行时间产生影响？（可以通过在代码中创建开始时间和结束时间来计算程序运行时间）
在我看来 maptask 参数的值会影响程序的运行时间，reducetask 参数的值则不会影响程序的运行时间。输入文本的大小是固定的，想要对其中的单词出现次数进行计数需要依次经过 Map 与 Reduce 两个阶段。Map 阶段的执行速度取决于 maptask 的大小，maptask 越大则将文件分片越多，每个分片中的内容越小，并且这些分片在多个线程上并行，执行速度就越快，反之则执行速度就越慢。Map 阶段执行完毕之后进入 Reduce 阶段，Reduce 阶段是对 Map 阶段的计算结果进行分类与合并，整体来说计算量较小，因而同一时间并行的线程数量多少对执行时间的影响并不显著。故 maptask 参数的值会影响程序的运行时间，但是 reducetask 参数的值则不会影响程序的运行时间。接下来对猜想进行验证。

由主程序中`wc = WordCount(2, 2, sys.argv[1])`可以得知，此时 maptask = 2，reducetask = 2，执行时间 = 3.448732376098633 秒（运行结果见图一）

接下来修改 maptask = 1，reducetask = 2 不变，执行时间 = 4.265958070755005 秒（运行结果见图二），可以发现运行时间明显增加。

接下来修改 maptask = 2 不变，reducetask = 1，执行时间 = 3.4649860858917236 秒（运行结果见图三），可以发现运行时间几乎不变。

接下来修改 maptask = 4，reducetask = 2 不变，执行时间 = 3.2155041694641113 秒（运行结果见图四），可以发现运行时间减少。

接下来修改 maptask = 2 不变，reducetask = 4，执行时间 = 3.486016273498535 秒（运行结果见图五），可以发现运行时间几乎不变。

猜想得到验证正确。

## 3. 遇到的问题及解决方式
无
## 4. 实验总结
通过本次实验，我深入理解了 MapReduce 框架的基本原理与执行流程，明确了 Map 阶段负责对原始数据进行拆分并提取键值对，Reduce 阶段对这些键值对进行聚合处理的机制。在代码层面，掌握了如何通过 multiprocessing.Pool 实现 Map 和 Reduce 阶段的 并发执行，并通过实验验证了并行度对性能的影响。

实验中，通过调整 maptask 和 reducetask 参数，我观察到 Map 阶段的任务数量对程序运行时间有显著影响，而 Reduce 阶段的任务数量影响较小。这不仅反映了 Map 阶段在数据处理中的工作量更大，还帮助我理解了并行系统中“瓶颈环节决定性能”这一设计思想。与此同时，我也掌握了使用 time 模块对程序执行时间进行测量的方法，这为后续性能调优提供了实用手段。

此外，在分析 Map() 和 Reduce() 方法参数时，我意识到工程实现中并非所有输入参数都会被实际使用，这提示我在阅读代码时应重点理解其设计意图而非表面调用形式。

整体而言，本实验不仅帮助我理解了分布式数据处理的核心思想和实际执行流程，也让我体验到了并发技术在性能提升方面的重要作用。未来在处理更复杂的分布式系统或大数据场景时，我能够更加理性地分析任务划分与并行策略，具备更强的系统设计能力。